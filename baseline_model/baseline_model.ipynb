{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2275640",
   "metadata": {},
   "source": [
    "1. Download and import the model\n",
    "\n",
    "Set-up a baseline form HuggingFace\n",
    "https://huggingface.co/alana89/TabSTAR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "013a56a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tabstar in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (1.1.2)\n",
      "Requirement already satisfied: joblib in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from tabstar) (1.5.2)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from tabstar) (2.3.5)\n",
      "Requirement already satisfied: pandas>=2.2.2 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from tabstar) (2.3.3)\n",
      "Requirement already satisfied: peft in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from tabstar) (0.18.0)\n",
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from tabstar) (1.7.2)\n",
      "Requirement already satisfied: skrub in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from tabstar) (0.7.0)\n",
      "Requirement already satisfied: torch>=2.6.0 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from tabstar) (2.9.1)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from tabstar) (4.67.1)\n",
      "Requirement already satisfied: transformers>=4.49.0 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from tabstar) (4.57.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/jeremiwasilewski/Library/Python/3.14/lib/python/site-packages (from pandas>=2.2.2->tabstar) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from pandas>=2.2.2->tabstar) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from pandas>=2.2.2->tabstar) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/jeremiwasilewski/Library/Python/3.14/lib/python/site-packages (from python-dateutil>=2.8.2->pandas>=2.2.2->tabstar) (1.17.0)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from torch>=2.6.0->tabstar) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from torch>=2.6.0->tabstar) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from torch>=2.6.0->tabstar) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from torch>=2.6.0->tabstar) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from torch>=2.6.0->tabstar) (3.6)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from torch>=2.6.0->tabstar) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from torch>=2.6.0->tabstar) (2025.10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from sympy>=1.13.3->torch>=2.6.0->tabstar) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from transformers>=4.49.0->tabstar) (0.36.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/jeremiwasilewski/Library/Python/3.14/lib/python/site-packages (from transformers>=4.49.0->tabstar) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from transformers>=4.49.0->tabstar) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from transformers>=4.49.0->tabstar) (2025.11.3)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from transformers>=4.49.0->tabstar) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from transformers>=4.49.0->tabstar) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from transformers>=4.49.0->tabstar) (0.7.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.49.0->tabstar) (1.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from jinja2->torch>=2.6.0->tabstar) (3.0.3)\n",
      "Requirement already satisfied: psutil in /Users/jeremiwasilewski/Library/Python/3.14/lib/python/site-packages (from peft->tabstar) (7.1.3)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from peft->tabstar) (1.12.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from requests->transformers>=4.49.0->tabstar) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from requests->transformers>=4.49.0->tabstar) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from requests->transformers>=4.49.0->tabstar) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from requests->transformers>=4.49.0->tabstar) (2025.11.12)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from scikit-learn->tabstar) (1.16.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from scikit-learn->tabstar) (3.6.0)\n",
      "Requirement already satisfied: matplotlib>=3.4.3 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from skrub->tabstar) (3.10.8)\n",
      "Requirement already satisfied: pydot in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from skrub->tabstar) (4.0.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from matplotlib>=3.4.3->skrub->tabstar) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from matplotlib>=3.4.3->skrub->tabstar) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from matplotlib>=3.4.3->skrub->tabstar) (4.61.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from matplotlib>=3.4.3->skrub->tabstar) (1.4.9)\n",
      "Requirement already satisfied: pillow>=8 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from matplotlib>=3.4.3->skrub->tabstar) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from matplotlib>=3.4.3->skrub->tabstar) (3.2.5)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install tabstar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4da373b",
   "metadata": {},
   "source": [
    "2. Read the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfadd93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "covtype_test = pd.read_csv(\"covtype_test.csv\")\n",
    "covtype_train = pd.read_csv(\"covtype_train.csv\")\n",
    "\n",
    "heloc_test = pd.read_csv(\"heloc_test.csv\")\n",
    "heloc_train = pd.read_csv(\"heloc_train.csv\")\n",
    "\n",
    "higgs_test = pd.read_csv(\"higgs_test.csv\")\n",
    "higgs_train = pd.read_csv(\"higgs_train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796d9204",
   "metadata": {},
   "source": [
    "3. Merge 3 datasets into one dataset for train\n",
    "\n",
    "The respecitve classes for this tabular problem are respective for the following datasets\n",
    "1) covtype - 6 different classes of tree\n",
    "2) heloc - binary class (good/ bad)\n",
    "3) higgs - binary class (signal / background)\n",
    "\n",
    "To aggregate these all classes we can notice that the whole problem consists of:\n",
    "- 7 classes for trees\n",
    "- 1 binary class where:\n",
    "    - \"1\" = good / signal\n",
    "    - \"0\" = bad / background\n",
    "\n",
    "This means that in order to keep track of the class we can combine all of the columns and mark the classes by additional outcome_class as follows:\n",
    "-  0 = bad / background for heloc / higggs \n",
    "- 1 = good / signal for heloc / higgs\n",
    "- 2 = Spruce/Fir\n",
    "- 3 = Lodgepole Pine\n",
    "- 4 = Ponderosa Pine\n",
    "- 5 = Cottonwood/Willow\n",
    "- 6 = Aspen\n",
    "- 7 = Douglas-fir\n",
    "- 8 = Krummholz\n",
    "\n",
    "This way the outcome_class with 9 integers can comprehehend 7 different classes for trees and binary class for 2 other datasets. The next step would be to design a table combining columns for all datasets and for each respective dataset it would mark the class accordingly to the mapping described above. \n",
    "\n",
    "Each row will consist of:\n",
    "- outcome_class = respective class for the case as indicated in the mapping above\n",
    "- features that are relevant to the class\n",
    "- other features not relevant to the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f001776c",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
       "      <th>...</th>\n",
       "      <th>PRI_met_sumet</th>\n",
       "      <th>PRI_jet_num</th>\n",
       "      <th>PRI_jet_leading_pt</th>\n",
       "      <th>PRI_jet_leading_eta</th>\n",
       "      <th>PRI_jet_leading_phi</th>\n",
       "      <th>PRI_jet_subleading_pt</th>\n",
       "      <th>PRI_jet_subleading_eta</th>\n",
       "      <th>PRI_jet_subleading_phi</th>\n",
       "      <th>PRI_jet_all_pt</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3351.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>726.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>3813.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>2271.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2732.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1082.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>912.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2572.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>957.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>2191.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2824.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>417.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>3223.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>6478.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2529.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1092.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>4983.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 110 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
       "0     3351.0   206.0   27.0                             726.0   \n",
       "1     2732.0   129.0    7.0                             212.0   \n",
       "2     2572.0    24.0    9.0                             201.0   \n",
       "3     2824.0    69.0   13.0                             417.0   \n",
       "4     2529.0    84.0    5.0                             120.0   \n",
       "\n",
       "   Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
       "0                           124.0                           3813.0   \n",
       "1                             1.0                           1082.0   \n",
       "2                            25.0                            957.0   \n",
       "3                            39.0                           3223.0   \n",
       "4                             9.0                           1092.0   \n",
       "\n",
       "   Hillshade_9am  Hillshade_Noon  Hillshade_3pm  \\\n",
       "0          192.0           252.0          180.0   \n",
       "1          231.0           236.0          137.0   \n",
       "2          216.0           222.0          142.0   \n",
       "3          233.0           214.0          110.0   \n",
       "4          227.0           231.0          139.0   \n",
       "\n",
       "   Horizontal_Distance_To_Fire_Points  ...  PRI_met_sumet  PRI_jet_num  \\\n",
       "0                              2271.0  ...            NaN          NaN   \n",
       "1                               912.0  ...            NaN          NaN   \n",
       "2                              2191.0  ...            NaN          NaN   \n",
       "3                              6478.0  ...            NaN          NaN   \n",
       "4                              4983.0  ...            NaN          NaN   \n",
       "\n",
       "   PRI_jet_leading_pt  PRI_jet_leading_eta  PRI_jet_leading_phi  \\\n",
       "0                 NaN                  NaN                  NaN   \n",
       "1                 NaN                  NaN                  NaN   \n",
       "2                 NaN                  NaN                  NaN   \n",
       "3                 NaN                  NaN                  NaN   \n",
       "4                 NaN                  NaN                  NaN   \n",
       "\n",
       "   PRI_jet_subleading_pt  PRI_jet_subleading_eta  PRI_jet_subleading_phi  \\\n",
       "0                    NaN                     NaN                     NaN   \n",
       "1                    NaN                     NaN                     NaN   \n",
       "2                    NaN                     NaN                     NaN   \n",
       "3                    NaN                     NaN                     NaN   \n",
       "4                    NaN                     NaN                     NaN   \n",
       "\n",
       "   PRI_jet_all_pt  Weight  \n",
       "0             NaN     NaN  \n",
       "1             NaN     NaN  \n",
       "2             NaN     NaN  \n",
       "3             NaN     NaN  \n",
       "4             NaN     NaN  \n",
       "\n",
       "[5 rows x 110 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# covytype\n",
    "# create mapping for covtype classes to new outcome_class\n",
    "covtype_map = {\n",
    "    1: 2,  \n",
    "    2: 3,  \n",
    "    3: 4,  \n",
    "    4: 5,  \n",
    "    5: 6,  \n",
    "    6: 7,  \n",
    "    7: 8,  \n",
    "}\n",
    "\n",
    "# make copy of covtype_train to avoid modifying original data\n",
    "covtype_train_copy = covtype_train.copy()\n",
    "\n",
    "covtype_train_copy[\"outcome_class\"] = covtype_train_copy[\"Cover_Type\"].map(covtype_map)\n",
    "covtype_train_copy = covtype_train_copy.drop(columns=[\"Cover_Type\"])\n",
    "\n",
    "# heloc \n",
    "heloc_train_copy = heloc_train.copy()\n",
    "heloc_train_copy[\"outcome_class\"] = heloc_train_copy[\"RiskPerformance\"].map({\n",
    "    \"Bad\": 0,\n",
    "    \"Good\": 1,\n",
    "})\n",
    "heloc_train_copy = heloc_train_copy.drop(columns=[\"RiskPerformance\"])\n",
    "\n",
    "# higgs data\n",
    "higgs_train_copy = higgs_train.copy()            \n",
    "higgs_train_copy[\"outcome_class\"] = higgs_train_copy[\"Label\"].map({\n",
    "    \"b\": 0,   \n",
    "    \"s\": 1,  \n",
    "})\n",
    "higgs_train_copy = higgs_train_copy.drop(columns=[\"Label\"])\n",
    "\n",
    "\n",
    "#  merge all 3 datasets into a single training set\n",
    "merged_train = pd.concat([covtype_train_copy, heloc_train_copy, higgs_train_copy], axis=0, ignore_index=True)\n",
    "merged_train.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9173c925",
   "metadata": {},
   "source": [
    "Let's check if numbers of classes in merged_train data match the numbers from original datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36156072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of rows with class 1\n",
    "count_class1 = int((merged_train[\"outcome_class\"] == 1).sum())\n",
    "count_class1 == sum(heloc_train[\"RiskPerformance\"] == \"Good\") +  sum(higgs_train[\"Label\"] == 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02e0a8e",
   "metadata": {},
   "source": [
    "The next step would be to merge the test datasets similarly to how the training datasets were merged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa07fafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "covtype_test_copy = covtype_test.copy()\n",
    "heloc_test_copy = heloc_test.copy()\n",
    "higgs_test_copy = higgs_test.copy() \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# merge datasets\n",
    "merged_test = pd.concat([covtype_test_copy, heloc_test_copy, higgs_test_copy], axis=0, ignore_index=True)\n",
    "\n",
    "# ensure that the columns in merged_test match those in t\n",
    "merged_test = merged_test.reindex(columns= merged_train.columns.drop(\"outcome_class\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2703eb6b",
   "metadata": {},
   "source": [
    "Once we have merged data for both train and test sets we can proceed to fit the model and get the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e60e0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into X and y\n",
    "y = merged_train[\"outcome_class\"].astype(int)\n",
    "X = merged_train.drop(columns=[\"outcome_class\"])\n",
    "\n",
    "\n",
    "# fill NaNs\n",
    "\n",
    "# train data\n",
    "X = X.fillna(-999)\n",
    "\n",
    "# test data\n",
    "merged_test = merged_test.fillna(-999)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f1249df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üñ•Ô∏è Using device: mps\n",
      "ü§© Loading pretrained model version: alana89/TabSTAR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 || Train 0.2783 || Val 0.2431 || Metric 0.9905  ü•á\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [1:46:15<1:46:15, 6375.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 || Train 0.2460 || Val 0.2429 || Metric 0.9905  ü•á\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÜ Best checkpoint: Epoch 2 with loss 0.2429\n",
      "Threshold: 0.2764 was chosen for best val loss of 0.2429\n",
      "üìä Averaging 2 checkpoints:\n",
      "- checkpoint_epoch_1.pt (val_loss=0.2431)\n",
      "- checkpoint_epoch_2.pt (val_loss=0.2429)\n",
      "üíæ Saved averaged checkpoint to .tabstar_checkpoint/20251212_132808/checkpoint_averaged.pt\n",
      "‚úÖ Saved averaged model to .tabstar_checkpoint/20251212_132808/averaged_model\n",
      "üìà Averaged checkpoint || Val Loss: 0.2430 || Val Metric: 0.9905\n"
     ]
    }
   ],
   "source": [
    "from tabstar.tabstar_model import TabSTARClassifier\n",
    "\n",
    "# get the model and fit it on the training data\n",
    "tabstar = TabSTARClassifier(max_epochs=2)\n",
    "tabstar.fit(X, y)\n",
    "\n",
    "# save the model\n",
    "tabstar.save(\"baseline3.pkl\")\n",
    "tabstar = TabSTARClassifier.load(\"baseline3.pkl\")\n",
    "\n",
    "\n",
    "# predict on the merged test set\n",
    "X_test = merged_test\n",
    "predictions = tabstar.predict(X_test) \n",
    "\n",
    "# save the predictions to a CSV file \n",
    "submission = pd.DataFrame({\n",
    "    \"ID\": range(1, len(predictions) + 1),\n",
    "    \"Prediction\": predictions.astype(int),\n",
    "})\n",
    "\n",
    "submission = submission[[\"ID\", \"Prediction\"]]\n",
    "submission.to_csv(\"combined_test_submission3.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4c10bc",
   "metadata": {},
   "source": [
    "To elaborate the comparison between the TabSTARClassifier and the LightGBM model we need to split the mergred train dataset into training and validation sets. This will allow us to evaluate the performance of tabstar on validation set and thus allow insights into quality of components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65ecbbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "tabstar = TabSTARClassifier.load(\"baseline_model.pkl\")\n",
    "predictions_val = tabstar.predict(X_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062e018b",
   "metadata": {},
   "source": [
    "After getting the local predictions we may summarise the results for each class using the table below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca2ee090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision  recall  f1-score\n",
      "bad/background          0.96    0.97      0.97\n",
      "good/signal             0.94    0.93      0.94\n",
      "Spruce/Fir              0.65    0.78      0.71\n",
      "Lodgepole Pine          0.78    0.68      0.73\n",
      "Ponderosa Pine          0.61    0.90      0.72\n",
      "Cottonwood/Willow       0.00    0.00      0.00\n",
      "Aspen                   0.00    0.00      0.00\n",
      "Douglas-fir             0.47    0.17      0.25\n",
      "Krummholz               0.66    0.64      0.65\n",
      "accuracy                0.89    0.89      0.89\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "\n",
    "name_map = {\n",
    "    \"0\":\"bad/background\",\"1\":\"good/signal\",\n",
    "    \"2\":\"Spruce/Fir\",\"3\":\"Lodgepole Pine\",\"4\":\"Ponderosa Pine\",\n",
    "    \"5\":\"Cottonwood/Willow\",\"6\":\"Aspen\",\"7\":\"Douglas-fir\",\"8\":\"Krummholz\"\n",
    "}\n",
    "\n",
    "resultsTable = pd.DataFrame(classification_report(y_val, predictions_val, output_dict=True, zero_division=0)).T\n",
    "resultsTable.index = resultsTable.index.map(lambda x: name_map.get(str(x), x))\n",
    "resultsTable = resultsTable.loc[:, [\"precision\",\"recall\",\"f1-score\"]].round(2)\n",
    "\n",
    "resultsTable = resultsTable.drop(index=[\"macro avg\", \"weighted avg\"])\n",
    "print(resultsTable)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
