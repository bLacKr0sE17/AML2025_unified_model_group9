{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "818123d1",
   "metadata": {},
   "source": [
    "#### Unified Tabular Benchmark (HELOC + HIGGS + COVTYPE)\n",
    "\n",
    "We train a single LightGBM multiclass model across three datasets by:\n",
    "1. Assigning a dataset identifier (`dataset_id`) so the model can account for dataset-specific label priors.\n",
    "2. Mapping all targets into one unified label space (11 classes total).\n",
    "3. Aligning feature spaces across datasets (missing features filled with 0).\n",
    "4. Removing suspicious identifier/proxy columns from HIGGS (`Weight/weight`, `EventId`) consistently in train and test.\n",
    "5. Using smoothed dataset + class reweighting to reduce dominance of large datasets/classes.\n",
    "\n",
    "Finally, we generate predictions for each dataset's test set and format them into Kaggleâ€™s required submission CSV.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "044592bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1f035e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Training Data\n",
    "heloc = pd.read_csv(\"heloc_train.csv\")\n",
    "covtype = pd.read_csv(\"covtype_train.csv\")\n",
    "higgs = pd.read_csv(\"higgs_train.csv\")\n",
    "\n",
    "# Drop identifier-like columns from HIGGS \n",
    "DROP_HIGGS_COLS = [\"Weight\", \"weight\", \"EventId\", \"EventID\"]\n",
    "for col in DROP_HIGGS_COLS:\n",
    "    if col in higgs.columns:\n",
    "        higgs = higgs.drop(columns=[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ab7a111e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Identifiers\n",
    "heloc[\"dataset_id\"] = 0\n",
    "covtype[\"dataset_id\"] = 1\n",
    "higgs[\"dataset_id\"] = 2\n",
    "\n",
    "# Global Target Encoding (11 classes total)\n",
    "# HELOC: Bad/Good - 0/1\n",
    "heloc[\"target\"] = heloc[\"RiskPerformance\"].map({\"Bad\": 0, \"Good\": 1})\n",
    "\n",
    "# HIGGS: b/s - 0/1 then shift by +2 - 2/3\n",
    "higgs[\"target\"] = higgs[\"Label\"].map({\"b\": 0, \"s\": 1}) + 2\n",
    "\n",
    "# COVTYPE: 1..7 shift by +3 - 4..10\n",
    "covtype[\"target\"] = covtype[\"Cover_Type\"] + 3\n",
    "\n",
    "# Remove original label columns\n",
    "heloc = heloc.drop(columns=[\"RiskPerformance\"])\n",
    "higgs = higgs.drop(columns=[\"Label\"])\n",
    "covtype = covtype.drop(columns=[\"Cover_Type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aea3daae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine feature sets (exclude metadata)\n",
    "heloc_features = [c for c in heloc.columns if c not in [\"target\", \"dataset_id\"]]\n",
    "covtype_features = [c for c in covtype.columns if c not in [\"target\", \"dataset_id\"]]\n",
    "higgs_features = [c for c in higgs.columns if c not in [\"target\", \"dataset_id\"]]\n",
    "\n",
    "ALL_FEATURES = sorted(set(heloc_features) | set(covtype_features) | set(higgs_features))\n",
    "\n",
    "def align_features_train(df):\n",
    "    df = df.copy()\n",
    "    for col in ALL_FEATURES:\n",
    "        if col not in df.columns:\n",
    "            df[col] = 0\n",
    "    return df[ALL_FEATURES + [\"dataset_id\", \"target\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2e48d104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align + combine training data\n",
    "heloc = align_features_train(heloc)\n",
    "covtype = align_features_train(covtype)\n",
    "higgs = align_features_train(higgs)\n",
    "\n",
    "full_data = pd.concat([heloc, covtype, higgs], ignore_index=True)\n",
    "\n",
    "X = full_data.drop(columns=[\"target\"])\n",
    "y = full_data[\"target\"]\n",
    "dataset_id = full_data[\"dataset_id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef4babd",
   "metadata": {},
   "source": [
    "### Smoothed reweighting\n",
    "\n",
    "We reduce imbalance by combining:\n",
    "- **Dataset weighting**: each dataset contributes similarly (prevents HIGGS from dominating).\n",
    "- **Smoothed class weighting**: uses `1/sqrt(class_count)` to avoid extreme weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f6017ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute smoothed weights\n",
    "dataset_counts = full_data[\"dataset_id\"].value_counts().to_dict()\n",
    "class_counts = full_data[\"target\"].value_counts().to_dict()\n",
    "\n",
    "weights = []\n",
    "for _, row in full_data.iterrows():\n",
    "    d = int(row[\"dataset_id\"])\n",
    "    y_i = int(row[\"target\"])\n",
    "\n",
    "    w = 1.0 / dataset_counts[d]\n",
    "    w = w * (1.0 / np.sqrt(class_counts[y_i]))  \n",
    "    weights.append(w)\n",
    "\n",
    "weights = np.array(weights, dtype=float)\n",
    "weights = weights / weights.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "62a3ce2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[207]\tvalid_0's multi_error: 0.220864\n",
      "Best iteration: 207\n"
     ]
    }
   ],
   "source": [
    "# Train/Validation split and early stopping\n",
    "X_train, X_val, y_train, y_val, d_train, d_val = train_test_split(\n",
    "    X, y, dataset_id,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=dataset_id\n",
    ")\n",
    "\n",
    "w_train = weights[X_train.index]\n",
    "w_val = weights[X_val.index]\n",
    "\n",
    "train_data = lgb.Dataset(X_train, label=y_train, weight=w_train)\n",
    "val_data = lgb.Dataset(X_val, label=y_val, weight=w_val)\n",
    "\n",
    "params = {\n",
    "    \"objective\": \"multiclass\",\n",
    "    \"num_class\": 11,\n",
    "    \"metric\": \"multi_error\",\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"num_leaves\": 63,\n",
    "    \"min_data_in_leaf\": 50,\n",
    "    \"feature_fraction\": 0.8,\n",
    "    \"bagging_fraction\": 0.8,\n",
    "    \"bagging_freq\": 1,\n",
    "    \"lambda_l2\": 1.0,\n",
    "    \"verbosity\": -1,\n",
    "    \"seed\": 42\n",
    "}\n",
    "\n",
    "model = lgb.train(\n",
    "    params,\n",
    "    train_data,\n",
    "    valid_sets=[val_data],\n",
    "    num_boost_round=2000,\n",
    "    callbacks=[lgb.early_stopping(50)]\n",
    ")\n",
    "\n",
    "best_iteration = model.best_iteration\n",
    "print(\"Best iteration:\", best_iteration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ed54cdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain final model on all data\n",
    "final_train_data = lgb.Dataset(X, label=y, weight=weights)\n",
    "\n",
    "final_model = lgb.train(\n",
    "    params,\n",
    "    final_train_data,\n",
    "    num_boost_round=best_iteration\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce6c1c8",
   "metadata": {},
   "source": [
    "## Prepare test sets\n",
    "\n",
    "We apply the same feature alignment as training, including:\n",
    "- add `dataset_id`\n",
    "- fill missing features with 0\n",
    "- remove HIGGS proxy/identifier columns consistently (`Weight/weight`, `EventId`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f769912c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data + drop proxy/ID\n",
    "heloc_test = pd.read_csv(\"heloc_test.csv\")\n",
    "covtype_test = pd.read_csv(\"covtype_test.csv\")\n",
    "higgs_test = pd.read_csv(\"higgs_test.csv\")\n",
    "\n",
    "# Drop the identifier-like columns from HIGGS TEST\n",
    "for col in DROP_HIGGS_COLS:\n",
    "    if col in higgs_test.columns:\n",
    "        higgs_test = higgs_test.drop(columns=[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0f9a858c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare test function\n",
    "def prepare_test(df, dataset_id_value):\n",
    "    df = df.copy()\n",
    "    df[\"dataset_id\"] = dataset_id_value\n",
    "    for col in ALL_FEATURES:\n",
    "        if col not in df.columns:\n",
    "            df[col] = 0\n",
    "    return df[ALL_FEATURES + [\"dataset_id\"]]\n",
    "\n",
    "heloc_test = prepare_test(heloc_test, 0)\n",
    "covtype_test = prepare_test(covtype_test, 1)\n",
    "higgs_test = prepare_test(higgs_test, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bb33c53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict and decode back to dataset label spaces\n",
    "heloc_preds = np.argmax(final_model.predict(heloc_test), axis=1)\n",
    "covtype_preds = np.argmax(final_model.predict(covtype_test), axis=1)\n",
    "higgs_preds = np.argmax(final_model.predict(higgs_test), axis=1)\n",
    "\n",
    "# Decode Predictions back to original label spaces\n",
    "heloc_final = heloc_preds                  \n",
    "higgs_final = higgs_preds - 2              \n",
    "covtype_final = covtype_preds - 3          "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fa7047",
   "metadata": {},
   "source": [
    "### Kaggle submission formatting\n",
    " \n",
    "We follow the provided ordering and offsets:\n",
    "- COVTYPE IDs start at 1\n",
    "- HELOC IDs start at 3501\n",
    "- HIGGS IDs start at 4547\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5c8631fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Prediction\n",
       "0   1           1\n",
       "1   2           1\n",
       "2   3           1\n",
       "3   4           1\n",
       "4   5           1"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Kaggle submission\n",
    "final_submission = pd.concat([\n",
    "    pd.DataFrame({\n",
    "        \"ID\": np.arange(1, 1 + len(covtype_final)),\n",
    "        \"Prediction\": covtype_final\n",
    "    }),\n",
    "    pd.DataFrame({\n",
    "        \"ID\": np.arange(3501, 3501 + len(heloc_final)),\n",
    "        \"Prediction\": heloc_final\n",
    "    }),\n",
    "    pd.DataFrame({\n",
    "        \"ID\": np.arange(4547, 4547 + len(higgs_final)),\n",
    "        \"Prediction\": higgs_final\n",
    "    })\n",
    "], ignore_index=True)\n",
    "\n",
    "final_submission.to_csv(\n",
    "    \"final_submission_unified_tabular_benchmark_group_09.csv\",\n",
    "    index=False\n",
    ")\n",
    "\n",
    "final_submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f550f369",
   "metadata": {},
   "source": [
    "# Sanity checks \n",
    "\n",
    "We include quick checks to ensure:\n",
    "- `dataset_id` alone cannot fully solve the problem (it only encodes dataset priors).\n",
    "- No single proxy feature (e.g., HIGGS Weight) provides suspiciously strong predictive power (we removed these).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d4c61fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using dataset_id only: 0.6181060965301115\n"
     ]
    }
   ],
   "source": [
    "# dataset_id-only sanity check\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_check = full_data[[\"dataset_id\"]]\n",
    "y_check = full_data[\"target\"]\n",
    "\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(\n",
    "    X_check, y_check, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "clf = LogisticRegression(max_iter=500)\n",
    "clf.fit(X_tr, y_tr)\n",
    "\n",
    "print(\"Accuracy using dataset_id only:\", accuracy_score(y_te, clf.predict(X_te)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b2e39a",
   "metadata": {},
   "source": [
    "Using `dataset_id` alone yields ~62% accuracy, reflecting differing class priors\n",
    "across datasets but not label leakage. In contrast, the HIGGS `Weight` feature\n",
    "exhibited unusually strong predictive power and was therefore excluded.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ccb0cf",
   "metadata": {},
   "source": [
    "# Results summary\n",
    "\n",
    "To investigate predictive accuracy per class, local predicitons will be further validated in the code below. It's worth to note to avoid data leakage, we can only use the model that has not been trained on complete dataset -> `model` not `final_model`. To optimise first version of the model `num_boost_round` was adjusted to identified best iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "570a0895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision  recall  f1-score\n",
      "bad                     0.73    0.76      0.74\n",
      "good                    0.71    0.68      0.70\n",
      "background              0.88    0.87      0.88\n",
      "signal                  0.76    0.78      0.77\n",
      "Spruce/Fir              0.86    0.85      0.85\n",
      "Lodgepole Pine          0.87    0.88      0.88\n",
      "Ponderosa Pine          0.89    0.91      0.90\n",
      "Cottonwood/Willow       0.87    0.85      0.86\n",
      "Aspen                   0.76    0.64      0.70\n",
      "Douglas-fir             0.78    0.78      0.78\n",
      "Krummholz               0.89    0.90      0.89\n",
      "accuracy                0.84    0.84      0.84\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model = lgb.train(\n",
    "    params,\n",
    "    train_data,\n",
    "    valid_sets=[val_data],\n",
    "    num_boost_round= best_iteration,\n",
    ")\n",
    "\n",
    "name_map = {\n",
    "    # HELOC\n",
    "    \"0\":  \"bad\",\n",
    "    \"1\":  \"good\",\n",
    "\n",
    "    # Higgs\n",
    "    \"2\":  \"background\",\n",
    "    \"3\":  \"signal\",\n",
    "\n",
    "    # COVTYPE \n",
    "    \"4\":  \"Spruce/Fir\",          \n",
    "    \"5\":  \"Lodgepole Pine\",      \n",
    "    \"6\":  \"Ponderosa Pine\",      \n",
    "    \"7\":  \"Cottonwood/Willow\",\n",
    "    \"8\":  \"Aspen\", \n",
    "    \"9\":  \"Douglas-fir\",         \n",
    "    \"10\": \"Krummholz\",           \n",
    "}\n",
    "\n",
    "predictions_val = np.argmax(model.predict(X_val), axis=1) \n",
    "\n",
    "resultsTab = pd.DataFrame(classification_report(y_val, predictions_val, output_dict=True, zero_division=0)).T\n",
    "resultsTab.index = resultsTab.index.map(lambda x: name_map.get(str(x), x))\n",
    "resultsTab = resultsTab.loc[:, [\"precision\", \"recall\", \"f1-score\"]].round(2)\n",
    "resultsTab = resultsTab.drop(index=[\"macro avg\", \"weighted avg\"], errors=\"ignore\")\n",
    "\n",
    "print(resultsTab)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
